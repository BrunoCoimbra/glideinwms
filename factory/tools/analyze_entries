#!/usr/bin/python
#
# analyze_entries_duration.py
# Analyzes the completed_jobs logs of today and yesterday for
# each entry point and averages the durations of glideins,
#    and records the number (fraction) of jobs which had
#    validation problems (validation=1000(s)) and for which
#    condor failed to start.
#        
# Alison McCrea
# Created 3.23.2010

import os, getopt, sys, time, re, fnmatch
import calendar, datetime
from time import localtime

# finds average durations of all jobs in a completed_jobs log
def avgDur(dur_times):

   duration_sum = 0
   
   for i in dur_times:
      dur_time = re.sub("\D", "", i)   # extract duration time
      duration_sum += int(dur_time)       # sum all durations for a log
   average = duration_sum/num_jobs   # average for a log (entry)
   durations[entry] = average 
   
# finds jobs for which condor failed to start
def condorStartFalse(falses):
   
   fraction = "%d/%d" % (len(falses), num_jobs)
   if len(falses) > 0:
      false_starts[entry] = fraction

# finds all jobs with validation problems (validation=1000)
def val(val_times):
  
   fraction = float(len(val_times))/float(num_jobs)
   if fraction > ratio:
      #if entry not in false_starts:
      if len(val_times) == num_jobs:
         fraction = 100
      else:
         fraction = fraction*100
      val_timeouts[entry] = "%d/%d (%d%%)" % (len(val_times), num_jobs, fraction)
   


def printReport():
   if one_entry == 0:
      file.write("\nGlidein Factory Log Analysis for " + date + ":\n\n")
      file.write( "Glidein factory name: %s\n" % gf)
      file.write( "Glidein factory location: %s\n" % factory_loc)

      file.write( "Checking jobs which completed within the past %d hours.\n" % h)

      file.write(  "-------------------------------------------------\n")
      file.write( "Entries with average glidein durations less than 3600s (1 hour)\n\n")
      for i in durations:
         if durations[i] < 3600:
            file.write( "Avg dur/%s:\t%d\n" % (i, durations[i]))
      
      file.write( "\n---------------------------------------------------\n")
      file.write( "Entries with average glidein durations greater than 3600s (1 hour)\n\n")
      for i in durations:
         if durations[i] > 3600:
            file.write( "Avg dur/%s:\t%d\n" % (i, durations[i]))

      file.write("---------------------------------------------------\n")
      file.write("\nAverage duration for all entry points: %d\n" % total_average)
     
      file.write( "\n---------------------------------------------------\n")
      file.write( "Number of jobs where condor failed to start / total jobs:\n")
      file.write( "(Note that all have 1000s validation times as well)\n\n" )
      for i in false_starts:       
         file.write( "%s: \t %s\n" % (i, false_starts[i]))

      file.write("\n---------------------------------------------------\n")
      file.write("Jobs with max validation times (1000s) / total jobs > %2f%%:\n\n" % (ratio*100))
      for i in val_timeouts:
         file.write( "%s: \t %s\n" % (i, val_timeouts[i]) )

      file.write( "\nDone.\n\n")

   elif one_entry == 1:
      file.write( "\nGlidein Factory Log Analysis for " + entries[0] + ", " + date + ":\n\n")
      file.write( "Glidein factory name: %s\n" % gf)
      file.write( "Glidein factory location: %s\n" % factory_loc)

      file.write(  "-------------------------------------------------\n")
      
      file.write( "Avgerage duration of glideins:\t%d\n" % durations[entries[0]])
      if len(false_starts) != 0:
         file.write( "Jobs where condor failed to start/total:\t%s\n" % false_starts[entries[0]])
      if len(val_timeouts) != 0:
         file.write( "Jobs with max validation times (1000s)/total:\t%s\n" % val_timeouts[entries[0]])

      file.write( "\nDone.\n\n")
   
   file.close()
   print "\ngf_log outputted to %s.\n" % outdir

def condorActivityLogs():

     #Search condor_activity logs for "Job held." 
     siteb = entry[5:len(entry)]
     cond_act_address = entry + "/log/condor_activity_" + today + siteb + "\\@" + gf + "*.log"
     if os.path.isfile(cond_act_address):
        infile = (cond_act_address)
        cond_act = infile.read()
        held = re.findall("held", cond_act)
        holds[entry] = len(held)

###############################################################################

if __name__ == "__main__":
   
   ratio = .5
   debug = 0      # don't output a report
   printall = 0   # print a special report for a single entry point
   one_entry = 0  # only one entry point
   condAct = 0

   outdir = os.environ['HOME'] # directory of outputted report
   gf = 'Production_v2_0'      # glidein factory name
   gf_base = "/home/gfactory/glideinsubmit"   # glidein factory base directory

   usage = '''
Usage:  -h: this help message.
    -r [int] : min % of failing jobs per site to be reported (default 50%)
    -e [ENTRY POINT]: run on a single entry point (example: entry_T2_US_UCSD)
    -d : debugging mode (do not generate a report)  
    -p : print all data instead of creating a report
 
    -t [int]: Check logs that completed within the previous X hours (up to 24)
    -y : check yesterday's logs
 
    Path Options (Exclude final / for all paths entered)
    -f [FACTORY NAME]: glidein factory name (default Production_v2_0)
    -s [FACTORY LOC]: base directory of glidein factory (default home/gfactory/glideinsubmit)
    -o [PATH]: path to generated log (dir must exist beforehand - default is user's home)

    -v : Analyze the condor_activity logs for jobs being held. No completed_jobs logs. 

    This script parses the completed_jobs_<today> log of each entry point for
       average duration of glideins, 
       glideins for which condor failed to start, 
       glideins with validation problems,
       and held jobs (-v option).
'''

   
   # todays date in form used in completed_jobs log
   today = time.strftime("%Y%m%d")      #yyyymmdd
   date = time.strftime("%m-%d-%Y_%H:%M:%S")
   yesterday = int(today)-1
   if debug == 1:
      print "today is", today
      print "date is", date
      print "yesterday is", yesterday

   h = 24   # jobs completed within the previous X hours reported

   try:
     opts, args = getopt.getopt( sys.argv[1:], 'hvdyr:e:o:f:s:t:')
   except getopt.GetoptError, err:
      print str(err)
      print usage
      sys.exit(2)
   output = None
   verbose = False

   for opt, arg in opts:
      if opt == "-r":
          if arg > 1.0:
             ratio = float(arg)/100.0
             print "ratio is %f" % ratio
          else: 
             ratio = arg
             print "ratio is %f" % ratio

      elif opt in ("-h", "-help", "--help"):
         print usage
         sys.exit()

      elif opt == "-e":
         factory_loc = gf_base + "/glidein_" + gf
         address = factory_loc+"/"+arg+"/log/completed_jobs_"+today+".log"
         if not os.path.isfile(address):
            print "\nMalformed entry point name.\n"
            sys.exit()
         else: 
            one_entry = 1
            sole_entry = [arg]
            ratio = 0.0    
 
      elif opt == "-y":
         today = int(today)-1

      elif opt == "-t":
         h = arg 

      elif opt == "-d":
         debug = 1

      elif opt == "-o":
         outdir = arg

      elif opt == "-f":
         gf = arg

      elif opt == "-s":
         gf_base = arg

      elif opt == "-v":
         condAct = 1

      else: 
         print "Invalid option. -h for help."
         sys.exit()

   # only create output file if not in debug mode
   if debug == 0:
      file_loc = outdir + "/gf_log_" + date
      file = open(file_loc, "w")

   #get time boundary - time after which glideins should be checked
   x = time.localtime()
   day = x[2]
   if debug ==1:
      print "h = ", h
      print "x2 = ", x[2]
      print "x3 = ", x[3]
   h = x[3] - int(h)

   check_yesterday = 0 
   # if X hours ago goes into yesterday, check yesterday's log as well
   if h < 0:
      day = x[2]-1
      h = 24 + h
      check_yesterday = 1
      if debug == 1:
         print "going into yesterday."
         print "day is", day
         print "hour is", h
   #   (year, mnth,  day,   hour,  min,  sec, ...)
   y = (x[0], x[1], day, h, x[4], x[5], x[6], x[7], x[8])

   if debug == 1:
      print "Checking glideins after ", y

   # Get list of entry points
   factory_loc = gf_base + "/glidein_" + gf
   os.chdir(factory_loc)
   dirList = os.listdir(os.getcwd())
   entries = []
   if one_entry == 1:
      entries = sole_entry
   else: 
      for dir in dirList:
         if fnmatch.fnmatch(dir, 'entry_*'):
            entries.append(dir)

   #if debug == 1:
      #for i in entries:
         #print i 
 
   if condAct == 1:
      holds = {}
      if debug == 1:
        print entries
      for entry in entries:
         condorActivityLogs()
      print "Entries held: ", holds
      sys.exit()
 
   durations = {}   # {'entry_name' : average glidein duration }
   false_starts = {}      # {'entry_name' : %/jobs false starts } 
   val_timeouts = {}      # {'entry_name' : %/jobs with validation=1000s } 

   
   total_average = 0   # average of all entries avg glidein duration
   total_logs = 0      # entries which have a compl jobs log today
 
   #unixtime = timeConverter.extractISO8601_Local(term[0])
   
   for entry in entries:
      address = os.getcwd()+"/"+entry+"/log/completed_jobs_"+today+".log"
      if os.path.isfile(address):
         total_logs += 1
         infile = open(address, "r")
         log = infile.read()

         if debug == 1:
            print "Checking ", entry, "..."

         # list of jobs for this entry point
         jobList = re.findall("<job.+", log)
         if debug == 1:
            print "jobList length for", entry, ":", len(jobList)
            #for i in jobList:
               #print i

         # if need yesterday's log for this entry point, add those to job list
         if check_yesterday == 1:
            yest_address = os.getcwd()+"/"+entry+"/log/completed_jobs_%d.log" % yesterday
            if os.path.isfile(yest_address):
               # total_logs += 1
               yest_infile = open(yest_address, "r")
               yest_log = yest_infile.read()
           
               # add jobs that completed yesterday to job list 
               # inserting at front of jobList keeps term times sequential
               yestjobList = re.findall("<job.+", yest_log)
               counter = 0
               for i in yestjobList:
                  jobList.insert(counter, i)
                  counter += 1
            else:
               if debug == 1:
                  print "yesterday's log does not exist for " + entry
 
         # will be filled with entries and corresponding data 
         jobdurs = {}
         start = {}
         vals = {}

         end_found = 0
         for i in jobList: #for each job,

         ## loop until jobs within time frame found ####################
         ## check if previous day's log needs to be checked as well. ### 

            if end_found == 0:
               termination = re.findall('terminated=".+-\d\d:00"', i)
               termination_time = re.findall("20.+-\d\d:00", termination[0])
   
               # next 5 lines taken from timeConversion.exportISO8601_Local()
               str = termination_time[0]
               timestr=str[:-6]
               tzstr=str[-6:]
               tzval=(long(tzstr[:3])*60+long(tzstr[4:]))*60
               x = calendar.timegm(time.strptime(timestr,"%Y-%m-%dT%H:%M:%S"))-tzval

               # check the termination time. If too long ago, skip this job. 
               #if debug==1:
                 # print "time of termination:", x
                 # print "Want to check glideins after:", time.mktime(y)
               if x < time.mktime(y):
                  continue
            
               # if the log is wanted, we know that all other logs after it
               # will also be wanted (chronological order)
               else:
                  end_found = 1
                  if debug == 1:
                     print "found surpassing time at", x

            
            dur_times = re.findall('duration="\d+"', i)
            num_jobs = len(dur_times)

            falses = re.findall('condor_started="False"', i)
            bad_vals = re.findall('validation="1000"', i)
            
            avgDur(dur_times)
            
            condorStartFalse(falses)    # returns the percentage of jobs
         
            val(bad_vals)

         total_average += durations[entry]


      else:
         if (one_entry == 1):
            print "\nNo completed_log for today for this entry point.\n"
         else: 
            continue   
  
   total_average = total_average/total_logs 
   
   if debug == 0:
      printReport()

   
###############################################################################

