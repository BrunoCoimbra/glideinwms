#!/bin/bash
#
# Project:
#   glideinWMS
#
# File Version: 
#

###########################
# Logging utility
#
# Every logged event is recorded in a separate file. Eventually, these shards
# are merged into a single log file; metadata is added at the beginning.

log_initialized=0
log_ready=0

# TODO: replace with a script-wise warning function
my_warn() {
    echo "$(date)" "$@" 1>&2
}

generate_glidein_metadata_json() {
    if command -v jq >/dev/null 2>&1; then
        json_metadata=$( jq -n \
                  --arg uuid "${glidein_uuid}" \
                  --arg name "${glidein_name}" \
                  --arg fact "${glidein_factory}" \
                  --arg entry "${glidein_entry}" \
                  --arg client "${client_name}" \
                  --arg client_group "${client_group}" \
                  --arg cred "${glidein_cred_id}" \
                  --arg cluster "${condorg_cluster}" \
                  --arg subcluster "${condorg_subcluster}" \
                  --arg schedd "${condorg_schedd}" \
                  --arg debug "${set_debug}" \
                  --arg startup_pid "$$" \
                  --arg tmpdir "${glide_tmp_dir}" \
                  --arg local_tmpdir "${glide_local_tmp_dir}" \
                  --arg proxy "${proxy_url}" \
                  --arg desc_file "${descript_file}" \
                  --arg desc_entry_file "${descript_entry_file}" \
                  --arg signature "${sign_id}" \
                  --arg entry_signature "${sign_entry_id}" \
                  '{UUID: $uuid, name: $name, factory: $fact, entry: $entry, client: $client, client_group: $client_group, cred_id: $cred, cluster: $cluster, subcluster: $subcluster, schedd: $schedd, debug: $debug, startup_pid: $startup_pid, tmpdir: $tmpdir, local_tmpdir: $local_tmpdir, proxy: $proxy, desc_file: $desc_file, desc_entry_file: $desc_entry_file, signature: $signature, entry_signature: $entry_signature}' )
    else
        json_metadata="{\"uuid\":\"${glidein_uuid}\", \"name\":\"${glidein_name}\", \"factory\":\"${glidein_factory}\", \"entry\":\"${glidein_entry}\", \"client\":\"${client_name}\", \"client_group\":\"${client_group}\", \"cred_id\":\"${glidein_cred_id}\", \"cluster\":\"${condorg_cluster}\", \"subcluster\":\"${condorg_subcluster}\", \"schedd\":\"${condorg_schedd}\",\"debug\":\"${set_debug}\", \"startup_pid\":\"$$\", \"tmpdir\":\"${glide_tmp_dir}\", \"local_tmpdir\":\"${glide_local_tmp_dir}\", \"proxy\":\"${proxy_url}\", \"desc_file\":\"${descript_file}\", \"desc_entry_file\":\"${descript_entry_file}\", \"signature\":\"${sign_id}\", \"entry_signature\":\"${sign_entry_id}\"}"  # TODO: escaping may be needed
    fi
    echo "${json_metadata}" > "${logdir}/glidein_metadata.json"
}

log_init() {
    # Initializes the log utility with the specified configuration.
    # This also creates the necessary folders, and should be called only once per glidein.
    # 1: glidein_uuid, 2: log_server_address, 3: relative basepath

    # Validate number of arguments
    if [ "$#" -ne 3 ]; then
        my_warn "log_init: could not initialize log. Expected 3 arguments, got $#."
        return 1
    fi

    # Inherit glidein_config from caller. It is necessary for logging to be properly configured.
    if [ ! -f "${glidein_config}" ]; then
        my_warn "log_init: glidein_config not defined in ${0}. Logging will not work here."
        return 1
    else
        add_config_line_source="$(grep '^ADD_CONFIG_LINE_SOURCE ' "${glidein_config}" | cut -d ' ' -f 2-)"
        source "${add_config_line_source}"
    fi

    logdir="logs/${1}" 
    stdout_logfile="${1}.out" 
    stderr_logfile="${1}.err" 
    log_logfile="${1}.log"
    logserver_addr="${2}"
    log_relative_basepath="${3}"

    # Export configuration
    add_config_line "GLIDEIN_LOGDIR" "${logdir}"
    add_config_line "GLIDEIN_STDOUT_LOGFILE" "${stdout_logfile}"
    add_config_line "GLIDEIN_STDERR_LOGFILE" "${stderr_logfile}"
    add_config_line "GLIDEIN_LOG_LOGFILE" "${log_logfile}"
    add_config_line "GLIDEIN_LOGSERVER_ADDR" "${logserver_addr}"
    add_config_line "GLIDEIN_LOG_RELATIVE_BASEPATH" "${log_relative_basepath}"

    # Create the necessary folders
    mkdir -p "${logdir}/shards/creating"

    # Create an 'empty' log, containing only glidein metadata
    generate_glidein_metadata_json
    echo "[" > "${logdir}/${log_logfile}"
    cat "${logdir}/glidein_metadata.json" >> "${logdir}/${log_logfile}"
    echo "]" >> "${logdir}/${log_logfile}"

    # Log a copy of stdout and stderr too
    exec >  >(tee -ia "${logdir}/${stdout_logfile}")
    exec 2> >(tee -ia "${logdir}/${stderr_logfile}" >&2)
    echo "$(date): Started logging stdout on file too"
    echo "$(date): Started logging stderr on file too" >&2

    add_config_line "GLIDEIN_LOG_INITIALIZED" "1"
}

function log_setup() {
    # Setup the logging utilities for the caller script with the specified configuration
    # 1: glidein config filename

    # Validate number of arguments
    if [ "$#" -ne 1 ]; then
        my_warn "log_setup: could not setup log for ${0}. Expected 1 arguments, got $#."
        return 1
    fi
    local glidein_config=${1}

    if [ ! -f "${glidein_config}" ]; then
        my_warn "log_setup: glidein_config not defined in ${0}. Logging will not work here."
        return 1
    fi

    log_initialized="$(grep '^GLIDEIN_LOG_INITIALIZED ' "${glidein_config}" | cut -d ' ' -f 2-)"
    if [ "${log_initialized}" != 1 ]; then
        my_warn "log_setup: apparently the logging configuration has not been initialiazed yet (${0}). Logging will not work here."
        return 1
    fi
    
    logdir="$(grep '^GLIDEIN_LOGDIR ' "${glidein_config}" | cut -d ' ' -f 2-)"
    stdout_logfile="$(grep '^GLIDEIN_STDOUT_LOGFILE ' "${glidein_config}" | cut -d ' ' -f 2-)"
    stderr_logfile="$(grep '^GLIDEIN_STDERR_LOGFILE ' "${glidein_config}" | cut -d ' ' -f 2-)"
    log_logfile="$(grep '^GLIDEIN_LOG_LOGFILE ' "${glidein_config}" | cut -d ' ' -f 2-)"
    logserver_addr="$(grep '^GLIDEIN_LOGSERVER_ADDR ' "${glidein_config}" | cut -d ' ' -f 2-)"
    log_relative_basepath="$(grep '^GLIDEIN_LOG_RELATIVE_BASEPATH ' "${glidein_config}" | cut -d ' ' -f 2-)"
    certdir="/etc/grid-security/certificates/"  # X509_CERT_DIR not available in glidein_config yet

    log_ready=1
}

json_escape() {
    # Escape json special characters
    qstr="$(printf '%s' "$1" | python -c 'import json,sys; print(json.dumps(sys.stdin.read()))')"
    # Remove unwanted outer double quotes
    qstr="${qstr%\"}"
    qstr="${qstr#\"}"
    echo "${qstr}"
}

get_logfile_path_relative() {

    if [ "${log_ready}" != 1 ]; then
        my_warn "get_logfile_path_relative: missing logging configuration in (${0}); perhaps forgot to call log_setup before?"
        return 1
    fi
    echo "${logdir}/${log_logfile}"
}

log_write() {
    # Log an event
    # 1:invoker, 2:type of message, 3:content/filepath, 4:severity
    # If type is file, then the filepath can be either absolute or relative to work_dir

    if [ "${log_ready}" != 1 ]; then
        my_warn "log_write: missing logging configuration in (${0}); perhaps forgot to call log_setup before?"
        return 1
    fi

    cur_time=$(date +%Y-%m-%dT%H:%M:%S%:z)
    cur_time_ns=$(date +%s%N)   # enough to ensure that shards have different timestamps

    # Source encoding utilities
    b64uuencode_source="$(grep '^B64UUENCODE_SOURCE ' "${glidein_config}" | cut -d ' ' -f 2-)"
    source "${b64uuencode_source}"

    # Argument $1
    invoker="$1"
    # Argument $2
    case $2 in
        "text" | "file" ) type=$2;;
        *) type="text";;
    esac
    # Argument $3
    if [ "$type" == "file" ]; then
        filename="$3"
        case ${filename} in
            /*) filepath="${filename}";;               # absolute
             *) filepath="${log_relative_basepath}/${filename}";;   # relative
        esac
        raw_content=$(cat "${filepath}")
        if [ -z "${raw_content}" ]; then
            raw_content="File not found"
        fi
        # Compression and encoding
        content=$(echo "${raw_content}" | gzip --stdout - | b64uuencode | tr -d '\n\r')
    else
        filename=""
        content="$3"
    fi
    # Argument $4
    case $4 in
        "error" | "warn" | "info" | "debug" | "fatal" ) severity=$4;;
        *) severity="info";;
    esac

    pid=${BASHPID:-$$}
    shard_filename="${cur_time_ns}_${invoker}_${pid}_${type}_${severity}.shard"

    pushd "${log_relative_basepath}/${logdir}/shards" > /dev/null
    touch "creating/${shard_filename}"
    if command -v jq >/dev/null 2>&1; then
        json_logevent=$( jq -n \
                  --arg inv "${invoker}" \
                  --arg pid "${pid}" \
                  --arg ts "${cur_time}" \
                  --arg ty "${type}" \
                  --arg fn "${filename}" \
                  --arg body "${content}" \
                  --arg sev "${severity}" \
                  '{invoker: $inv, pid: $pid, timestamp: $ts, severity: $sev, type: $ty, filename: $fn, content: $body}' )
    else
        invoker="$(json_escape "${invoker}")"
        content="$(json_escape "${content}")"
        json_logevent="{\"invoker\":\"${invoker}\", \"pid\":\"${pid}\", \"timestamp\":\"${cur_time}\", \"severity\":\"${severity}\", \"type\":\"${type}\", \"filename\":\"${filename}\", \"content\":\"${content}\"}"
    fi

    # Make sure that shards in the main dir have been fully written
    echo "${json_logevent}" > "creating/${shard_filename}"
    mv "creating/${shard_filename}" "${shard_filename}"
    popd > /dev/null
}

log_coalesce_shards() {
    # Merge log shards in a single file (for each glidein process)

    if [ "${log_ready}" != 1 ]; then
        my_warn "log_coalesce_shards: missing logging configuration in (${0}); perhaps forgot to call log_setup before?"
        return 1
    fi

    pushd "${log_relative_basepath}/${logdir}" > /dev/null

    # Skip if another process is already coaleascing
    if mkdir shards/coalescing; then
        cur_time=$(date +%Y-%m-%dT%H:%M:%S%:z)
        # Skip if there are no shards
        if [ -n "$(find shards -maxdepth 1 -type f)" ]; then
            cp "${log_logfile}" shards/coalescing/
            mv shards/*.shard shards/coalescing/
            pushd shards/coalescing > /dev/null
            sed -i '$ {s/]$/,/}' "${log_logfile}"   # replace last square bracket with comma
            for shd in *.shard; do                  # concatenate separating with comma
                cat "${shd}"
                echo ","
            done >> "${log_logfile}"
            sed -i '$ d' "${log_logfile}"           # remove last comma
            echo "]" >> "${log_logfile}"            # closing square bracket
            popd > /dev/null
            mv "shards/coalescing/${log_logfile}" .
        fi
    rm -rf shards/coalescing
    fi
    popd > /dev/null
}

send_logs_to_remote() {
    # Forward the logs to a remote HTTP server.
    # Note: implicitly merges the shards too

    log_coalesce_shards

    # Upload stdout log file
    curl_resp=$(curl -X PUT --capath "${certdir}" --upload-file "${log_relative_basepath}/${logdir}/${stdout_logfile}" "${logserver_addr}/${stdout_logfile}" 2>&1)
    curl_retval=$?
    if [ ${curl_retval} -ne 0 ]; then
        curl_version=$(curl --version 2>&1 | head -1)
        my_warn "${curl_cmd} failed. version: ${curl_version} exit_code: ${curl_retval} stderr: ${curl_resp}"
    fi

    # Upload stderr log file
    curl_resp=$(curl -X PUT --capath "${certdir}" --upload-file "${log_relative_basepath}/${logdir}/${stderr_logfile}" "${logserver_addr}/${stderr_logfile}" 2>&1)
    curl_retval=$?
    if [ ${curl_retval} -ne 0 ]; then
        curl_version=$(curl --version 2>&1 | head -1)
        my_warn "${curl_cmd} failed. version: ${curl_version} exit_code: ${curl_retval} stderr: ${curl_resp}"
    fi

    # Upload general log file
    curl_resp=$(curl -X PUT --capath "${certdir}" --upload-file "${log_relative_basepath}/${logdir}/${log_logfile}" "${logserver_addr}/${log_logfile}" 2>&1)
    curl_retval=$?
    if [ ${curl_retval} -ne 0 ]; then
        curl_version=$(curl --version 2>&1 | head -1)
        my_warn "${curl_cmd} failed. version: ${curl_version} exit_code: ${curl_retval} stderr: ${curl_resp}"
    fi
}

